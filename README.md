# pythonscrape


*Stack used :

* Firebse Hosting 
* Aws Lambda 
* Asw S3 bucket 
* React Js 

* Websites Scraped : 
Website 1: https://yofreesamples.com(have more than 20 coupons updated in a 72 hrs )
Website 3 : https://freesoff.com(have more than 20 coupons updated in a 72 hrs )
Website 2 : https://999coursesale.com(have more than 20 coupons updated in a 72 hrs )



*Bugs to fix :
1) all the backend functions are running on async mode one it is started it cant be stoped which effects the verbose method .
Possible solution >  E2C elastic load balancing can help in this process .
2) third party api services are on trail . scrapingbee api provides only 1000 credits . Possible way to fix this is running head less selenium on the backend 
3) Ui minor error on listing part 

*Future  improvment :
1) Notification when the max count reached 
2) File rename options while downloading . 
3) option to terminate the process and clear the data from backend .
4) removal of duplicated entries.

 
